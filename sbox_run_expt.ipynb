{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# run_expt.py contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "SyntaxError",
     "evalue": "invalid syntax (version.py, line 20)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;36m  File \u001b[0;32m\"wilds/version.py\"\u001b[0;36m, line \u001b[0;32m20\u001b[0m\n\u001b[0;31m    f'The WILDS package is out of date. Your version is {__version__}, while the latest version is {latest}.')\u001b[0m\n\u001b[0m                                                                                                            ^\u001b[0m\n\u001b[0;31mSyntaxError\u001b[0m\u001b[0;31m:\u001b[0m invalid syntax\n"
     ]
    }
   ],
   "source": [
    "import os, csv\n",
    "import time\n",
    "import argparse\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torchvision\n",
    "import sys\n",
    "from collections import defaultdict\n",
    "\n",
    "from wilds.common.data_loaders import get_train_loader, get_eval_loader\n",
    "from wilds.common.grouper import CombinatorialGrouper\n",
    "\n",
    "from utils import set_seed, Logger, BatchLogger, log_config, ParseKwargs, load, initialize_wandb, log_group_data, parse_bool\n",
    "from train import train, evaluate\n",
    "from algorithms.initializer import initialize_algorithm\n",
    "from transforms import initialize_transform\n",
    "from configs.utils import populate_defaults\n",
    "import configs.supported as supported"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Initialize dataset object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "57.8772239685\n",
      "66.8270189762\n"
     ]
    }
   ],
   "source": [
    "import numpy as np, pandas as pd, os, time, torch, torchvision\n",
    "data_dir = '/oak/stanford/groups/akundaje/abalsubr/DREAM/wilds/codalab_archive/'\n",
    "tf = 'MAX'\n",
    "itime = time.time()\n",
    "train_chr = pd.read_csv(os.path.join(data_dir, 'labels/{}.train.labels.tsv.gz'.format(tf)), sep='\\t')\n",
    "print(time.time() - itime)\n",
    "val_chr = pd.read_csv(os.path.join(data_dir, 'labels/{}.val.labels.tsv.gz'.format(tf)), sep='\\t')\n",
    "print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_celltypes = ['H1-hESC', 'HCT116', 'HeLa-S3', 'HepG2', 'K562']\n",
    "val_celltype = ['A549']\n",
    "test_celltype = ['GM12878']\n",
    "all_celltypes = train_celltypes + val_celltype + test_celltype\n",
    "\n",
    "metadata_map = {}\n",
    "metadata_map['chr'] = ['chr1', 'chr2', 'chr3', 'chr4', 'chr5', 'chr6', 'chr7', 'chr8', 'chr9', 'chr10', 'chr11', 'chr12', 'chr13', 'chr14', 'chr15', 'chr16', 'chr17', 'chr18', 'chr19', 'chr20', 'chr21', 'chr22', 'chrX']\n",
    "metadata_map['celltype'] = all_celltypes\n",
    "\n",
    "_split_dict = {\n",
    "    'train': 0,\n",
    "    'val-id': 1,\n",
    "    'test': 2,\n",
    "    'val-ood': 3\n",
    "}\n",
    "_split_names = {\n",
    "    'train': 'Train',\n",
    "    'val-id': 'Validation (ID)',\n",
    "    'test': 'Test',\n",
    "    'val-ood': 'Validation (OOD)'\n",
    "}\n",
    "_split_scheme = 'standard'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('H1-hESC', 25.299736976623535)\n",
      "('HCT116', 49.68733310699463)\n",
      "('HeLa-S3', 74.65905213356018)\n",
      "('HepG2', 99.33112812042236)\n",
      "('K562', 124.1327919960022)\n",
      "('A549', 149.19999814033508)\n",
      "('GM12878', 174.0277030467987)\n"
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "sequence_filename = os.path.join(data_dir, 'sequence.npz')\n",
    "seq_arr = np.load(sequence_filename)\n",
    "print(time.time() - itime)\n",
    "\n",
    "itime = time.time()\n",
    "_seq_bp = {}\n",
    "for chrom in seq_arr:\n",
    "    _seq_bp[chrom] = seq_arr[chrom]\n",
    "    print(chrom, time.time() - itime)\n",
    "itime = time.time()\n",
    "_dnase_allcelltypes = {}\n",
    "for ct in all_celltypes:\n",
    "    dnase_filename = os.path.join(data_dir, '{}_dnase.npz'.format(ct))\n",
    "    dnase_npz_file = np.load(dnase_filename)\n",
    "    _dnase_allcelltypes[ct] = {}\n",
    "    for chrom in _seq_bp:\n",
    "        _dnase_allcelltypes[ct][chrom] = dnase_npz_file[chrom]\n",
    "    print(ct, time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class Beagle(nn.Module):\n",
    "    \"\"\"\n",
    "    Neural net models over genomic sequence.\n",
    "    Input:\n",
    "        - sequence_length: int (default 1000) \n",
    "        - Shape: (N, 5, sequence_length, 1) with batch size N.\n",
    "    \n",
    "    Output:\n",
    "        - prediction (Tensor): float torch tensor of shape (N, )\n",
    "    \n",
    "    TODO: Finish docstring.\n",
    "    \"\"\"\n",
    "    def __init__(self):\n",
    "        \"\"\"\n",
    "        Parameters\n",
    "        ----------\n",
    "        sequence_length : int\n",
    "        n_genomic_features : int\n",
    "        \"\"\"\n",
    "        super(Beagle, self).__init__()\n",
    "\n",
    "        self.dropout = 0.3\n",
    "        self.num_cell_types = 1\n",
    "        self.conv1 = nn.Conv2d(5, 300, (19, 1), stride = (1, 1), padding=(9,0))\n",
    "        self.conv2 = nn.Conv2d(300, 200, (11, 1), stride = (1, 1), padding = (5,0))\n",
    "        self.conv3 = nn.Conv2d(200, 200, (7, 1), stride = (1, 1), padding = (4,0))\n",
    "        self.bn1 = nn.BatchNorm2d(300)\n",
    "        self.bn2 = nn.BatchNorm2d(200)\n",
    "        self.bn3 = nn.BatchNorm2d(200)\n",
    "        self.maxpool1 = nn.MaxPool2d((3, 1))\n",
    "        self.maxpool2 = nn.MaxPool2d((4, 1))\n",
    "        self.maxpool3 = nn.MaxPool2d((4, 1))\n",
    "\n",
    "        self.fc1 = nn.Linear(4200, 1000)\n",
    "        self.bn4 = nn.BatchNorm1d(1000)\n",
    "\n",
    "        self.fc2 = nn.Linear(1000, 1000)\n",
    "        self.bn5 = nn.BatchNorm1d(1000)\n",
    "\n",
    "        self.fc3 = nn.Linear(1000, self.num_cell_types)\n",
    "\n",
    "    def forward(self, s):\n",
    "        s = s.permute(0, 2, 1).contiguous()                          # batch_size x 5 x 1000\n",
    "        s = s.view(-1, 5, 1000, 1)                                   # batch_size x 5 x 1000 x 1 [5 channels]\n",
    "        s = self.maxpool1(F.relu(self.bn1(self.conv1(s))))           # batch_size x 300 x 333 x 1\n",
    "        s = self.maxpool2(F.relu(self.bn2(self.conv2(s))))           # batch_size x 200 x 83 x 1\n",
    "        s = self.maxpool3(F.relu(self.bn3(self.conv3(s))))           # batch_size x 200 x 21 x 1\n",
    "        s = s.view(-1, 4200)\n",
    "        conv_out = s\n",
    "\n",
    "        s = F.dropout(F.relu(self.bn4(self.fc1(s))), p=self.dropout, training=self.training)  # batch_size x 1000\n",
    "        s = F.dropout(F.relu(self.bn5(self.fc2(s))), p=self.dropout, training=self.training)  # batch_size x 1000\n",
    "        \n",
    "        s = self.fc3(s)\n",
    "\n",
    "        return s, conv_out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('nnet.0.weight', 33280),\n",
       " ('nnet.0.bias', 320),\n",
       " ('bdlstm.0.weight_ih_l0', 409600),\n",
       " ('bdlstm.0.weight_hh_l0', 409600),\n",
       " ('bdlstm.0.bias_ih_l0', 1280),\n",
       " ('bdlstm.0.bias_hh_l0', 1280),\n",
       " ('bdlstm.0.weight_ih_l0_reverse', 409600),\n",
       " ('bdlstm.0.weight_hh_l0_reverse', 409600),\n",
       " ('bdlstm.0.bias_ih_l0_reverse', 1280),\n",
       " ('bdlstm.0.bias_hh_l0_reverse', 1280),\n",
       " ('classifier.1.weight', 592000),\n",
       " ('classifier.1.bias', 925),\n",
       " ('classifier.3.weight', 4625),\n",
       " ('classifier.3.bias', 5)]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def count_parameters(model):\n",
    "    return sum(p.numel() for p in model.parameters() if p.requires_grad)\n",
    "\n",
    "model = Beagle2()\n",
    "model = DanQ(50, 5)\n",
    "\n",
    "lst = [(x[0], x[1].numel()) for x in model.named_parameters()]\n",
    "#np.sum([x[1] for x in lst])\n",
    "count_parameters(model)\n",
    "lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "'module' object has no attribute 'isin'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mAttributeError\u001b[0m                            Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-48-eeaf4b928825>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mtr_chrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'chr2'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chr9'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chr11'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mte_chrs\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m'chr1'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chr8'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'chr21'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 3\u001b[0;31m \u001b[0mtraining_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtrain_chr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_chr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtr_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      4\u001b[0m \u001b[0mval_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mval_chr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0misin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mval_chr\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'chr'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mte_chrs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0mall_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mconcat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mtraining_df\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_df\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mAttributeError\u001b[0m: 'module' object has no attribute 'isin'"
     ]
    }
   ],
   "source": [
    "tr_chrs = ['chr2', 'chr9', 'chr11']\n",
    "te_chrs = ['chr1', 'chr8', 'chr21']\n",
    "training_df = train_chr[np.isin(train_chr['chr'], tr_chrs)]\n",
    "val_df = val_chr[np.isin(val_chr['chr'], te_chrs)]\n",
    "all_df = pd.concat([training_df, val_df])\n",
    "\n",
    "#filter_msk = all_df['start'] >= 0\n",
    "filter_msk = all_df['start']%1000 == 0\n",
    "all_df = all_df[filter_msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.12.1\n"
     ]
    }
   ],
   "source": [
    "print(np.__version__)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/abalsubr/anaconda2/envs/scs3/lib/python3.6/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.659163236618042\n"
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "pd_list = []\n",
    "for ct in all_celltypes:\n",
    "    tc_chr = all_df[['chr', 'start', 'stop', ct]]\n",
    "    tc_chr.columns = ['chr', 'start', 'stop', 'y']\n",
    "    tc_chr['celltype'] = ct\n",
    "    pd_list.append(tc_chr)\n",
    "metadata_df = pd.concat(pd_list)\n",
    "print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.0391879081726074\n"
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "y_array = metadata_df['y'].replace({'U': 0, 'B': 1, 'A': -1}).values\n",
    "non_ambig_mask = (y_array != -1)\n",
    "metadata_df['y'] = y_array\n",
    "_metadata_df = metadata_df[non_ambig_mask]\n",
    "_y_array = torch.LongTensor(y_array[non_ambig_mask])\n",
    "print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "12.390011310577393\n"
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "chr_ints = _metadata_df['chr'].replace(dict( [(y, x) for x, y in enumerate(metadata_map['chr'])] )).values\n",
    "celltype_ints = _metadata_df['celltype'].replace(dict( [(y, x) for x, y in enumerate(metadata_map['celltype'])] )).values\n",
    "print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/users/abalsubr/anaconda2/envs/scs3/lib/python3.6/site-packages/ipykernel_launcher.py:12: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if sys.path[0] == '':\n"
     ]
    }
   ],
   "source": [
    "train_chr_mask = np.isin(_metadata_df['chr'], tr_chrs)\n",
    "val_chr_mask = np.isin(_metadata_df['chr'], te_chrs)\n",
    "train_celltype_mask = np.isin(_metadata_df['celltype'], train_celltypes)\n",
    "val_celltype_mask = np.isin(_metadata_df['celltype'], val_celltype)\n",
    "test_celltype_mask = np.isin(_metadata_df['celltype'], test_celltype)\n",
    "\n",
    "split_array = -1*np.ones(_metadata_df.shape[0]).astype(int)\n",
    "split_array[np.logical_and(train_chr_mask, train_celltype_mask)] = _split_dict['train']\n",
    "split_array[np.logical_and(val_chr_mask, test_celltype_mask)] = _split_dict['test']\n",
    "split_array[np.logical_and(val_chr_mask, val_celltype_mask)] = _split_dict['val-ood']\n",
    "split_array[np.logical_and(val_chr_mask, train_celltype_mask)] = _split_dict['val-id']\n",
    "_metadata_df['split'] = split_array\n",
    "_split_array = split_array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# get_input (idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = 3\n",
    "this_metadata = _metadata_df.iloc[idx, :]\n",
    "\n",
    "itime = time.time()\n",
    "flank_size = 400\n",
    "interval_start = this_metadata['start'] - flank_size\n",
    "interval_end = this_metadata['stop'] + flank_size\n",
    "dnase_this = _dnase_allcelltypes[this_metadata['celltype']][this_metadata['chr']][interval_start:interval_end]\n",
    "seq_this = _seq_bp[this_metadata['chr']][interval_start:interval_end]\n",
    "data = np.column_stack([seq_this, dnase_this])\n",
    "# print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4600"
      ]
     },
     "execution_count": 154,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.shape\n",
    "interval_end\n",
    "# itime = time.time()\n",
    "# np.save(os.path.join(data_dir, 'stmp.npy'), sa)\n",
    "# print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-78-0d033f8312a9>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mitime\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      2\u001b[0m metadata_array = torch.stack(\n\u001b[0;32m----> 3\u001b[0;31m     (torch.LongTensor(metadata_df['chr'].values), \n\u001b[0m\u001b[1;32m      4\u001b[0m      \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mLongTensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmetadata_df\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'celltype'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m      self._y_array),\n",
      "\u001b[0;31mTypeError\u001b[0m: can't convert np.ndarray of type numpy.object_. The only supported types are: float64, float32, float16, complex64, complex128, int64, int32, int16, int8, uint8, and bool."
     ]
    }
   ],
   "source": [
    "itime = time.time()\n",
    "metadata_array = torch.stack(\n",
    "    (torch.LongTensor(chr_ints), \n",
    "     torch.LongTensor(celltype_ints), \n",
    "     _y_array),\n",
    "    dim=1)\n",
    "print(time.time() - itime)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name '_metadata_array' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-156-6a2dab26072a>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0m_metadata_array\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m: name '_metadata_array' is not defined"
     ]
    }
   ],
   "source": [
    "_metadata_array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from examples.models.model_attributes import model_attributes"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
