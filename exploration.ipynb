{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20052024\n"
     ]
    }
   ],
   "source": [
    "!j=\"$( date '+%d%m%Y' )\"\n",
    "!echo $j\n",
    "# TODO: Pass the model prefix as a name to weight and biases. \n",
    "# I think we just take the fold and dataset, and then the time down to the minute to make the name for weights and biases"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'fold': 'B'}\n",
      "{'fold': 'B', 'no_nl': False, 'use_ood_val': True}\n"
     ]
    }
   ],
   "source": [
    "!python examples/run_expt.py --dataset poverty --dataset_kwargs fold=A --algorithm ERM --root_dir data --model vit_b_16 --progress_bar --n_epochs 10 --save_best --use_wandb --wandb_kwargs project=231n    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "device: cuda\n",
      "Dataset: poverty\n",
      "Algorithm: ERM\n",
      "Root dir: data\n",
      "Split scheme: official\n",
      "Dataset kwargs: {'no_nl': False, 'fold': 'A', 'use_ood_val': True}\n",
      "Download: False\n",
      "Frac: 1.0\n",
      "Version: None\n",
      "Unlabeled split: None\n",
      "Unlabeled version: None\n",
      "Use unlabeled y: False\n",
      "Loader kwargs: {'num_workers': 4, 'pin_memory': True}\n",
      "Unlabeled loader kwargs: {'num_workers': 8, 'pin_memory': True}\n",
      "Train loader: standard\n",
      "Uniform over groups: False\n",
      "Distinct groups: None\n",
      "N groups per batch: 8\n",
      "Unlabeled n groups per batch: 4\n",
      "Batch size: 64\n",
      "Unlabeled batch size: 64\n",
      "Eval loader: standard\n",
      "Gradient accumulation steps: 1\n",
      "Model: vit_b_16\n",
      "Model kwargs: {'num_channels': 8}\n",
      "Noisystudent add dropout: None\n",
      "Noisystudent dropout rate: None\n",
      "Pretrained model path: None\n",
      "Load featurizer only: False\n",
      "Teacher model path: None\n",
      "Transform: poverty\n",
      "Additional train transform: None\n",
      "Target resolution: None\n",
      "Resize scale: None\n",
      "Max token length: None\n",
      "Randaugment n: 2\n",
      "Loss function: mse\n",
      "Loss kwargs: {}\n",
      "Groupby fields: ['country']\n",
      "Group dro step size: None\n",
      "Coral penalty weight: 0.1\n",
      "Dann penalty weight: 0.1\n",
      "Dann classifier lr: 0.001\n",
      "Dann featurizer lr: 0.0001\n",
      "Dann discriminator lr: 0.001\n",
      "Afn penalty weight: None\n",
      "Safn delta r: None\n",
      "Hafn r: None\n",
      "Use hafn: False\n",
      "Irm lambda: 1.0\n",
      "Irm penalty anneal iters: None\n",
      "Self training lambda: None\n",
      "Self training threshold: None\n",
      "Pseudolabel t2: None\n",
      "Soft pseudolabels: False\n",
      "Algo log metric: mse\n",
      "Process pseudolabels function: pseudolabel_identity\n",
      "Val metric: r_wg\n",
      "Val metric decreasing: False\n",
      "N epochs: 10\n",
      "Optimizer: Adam\n",
      "Lr: 0.001\n",
      "Weight decay: 0.0\n",
      "Max grad norm: 1.0\n",
      "Optimizer kwargs: {}\n",
      "Scheduler: StepLR\n",
      "Scheduler kwargs: {'gamma': 0.96, 'step_size': 1}\n",
      "Scheduler metric split: val\n",
      "Scheduler metric name: None\n",
      "Process outputs function: None\n",
      "Evaluate all splits: True\n",
      "Eval splits: []\n",
      "Eval only: True\n",
      "Eval epoch: None\n",
      "Device: cuda\n",
      "Seed: 0\n",
      "Log dir: ./logs\n",
      "Log every: 50\n",
      "Save step: None\n",
      "Save best: True\n",
      "Save last: True\n",
      "Save pred: True\n",
      "No group logging: False\n",
      "Progress bar: True\n",
      "Resume: False\n",
      "Use wandb: False\n",
      "Wandb api key path: None\n",
      "Wandb kwargs: {}\n",
      "Use data parallel: False\n",
      "\n",
      "Train data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 484\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 394\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 501\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 1535\n",
      "    country = lesotho: n = 658\n",
      "    country = malawi: n = 1614\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 741\n",
      "    country = nigeria: n = 1206\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 488\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 274\n",
      "    country = uganda: n = 638\n",
      "    country = zambia: n = 586\n",
      "    country = zimbabwe: n = 678\n",
      "ID Val data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 45\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 49\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 59\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 141\n",
      "    country = lesotho: n = 66\n",
      "    country = malawi: n = 171\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 72\n",
      "    country = nigeria: n = 121\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 47\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 32\n",
      "    country = uganda: n = 67\n",
      "    country = zambia: n = 63\n",
      "    country = zimbabwe: n = 67\n",
      "ID Test data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 47\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 49\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 54\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 154\n",
      "    country = lesotho: n = 70\n",
      "    country = malawi: n = 172\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 66\n",
      "    country = nigeria: n = 123\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 50\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 24\n",
      "    country = uganda: n = 73\n",
      "    country = zambia: n = 70\n",
      "    country = zimbabwe: n = 48\n",
      "OOD Val data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 746\n",
      "    country = burkina_faso: n = 789\n",
      "    country = cameroon: n = 0\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 0\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 0\n",
      "    country = guinea: n = 300\n",
      "    country = kenya: n = 0\n",
      "    country = lesotho: n = 0\n",
      "    country = malawi: n = 0\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 0\n",
      "    country = nigeria: n = 0\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 0\n",
      "    country = sierra_leone: n = 435\n",
      "    country = tanzania: n = 1639\n",
      "    country = togo: n = 0\n",
      "    country = uganda: n = 0\n",
      "    country = zambia: n = 0\n",
      "    country = zimbabwe: n = 0\n",
      "OOD Test data...\n",
      "    country = angola: n = 855\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 0\n",
      "    country = cote_d_ivoire: n = 341\n",
      "    country = democratic_republic_of_congo: n = 0\n",
      "    country = ethiopia: n = 1193\n",
      "    country = ghana: n = 0\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 0\n",
      "    country = lesotho: n = 0\n",
      "    country = malawi: n = 0\n",
      "    country = mali: n = 590\n",
      "    country = mozambique: n = 0\n",
      "    country = nigeria: n = 0\n",
      "    country = rwanda: n = 984\n",
      "    country = senegal: n = 0\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 0\n",
      "    country = uganda: n = 0\n",
      "    country = zambia: n = 0\n",
      "    country = zimbabwe: n = 0\n",
      "vit_b_16 model inititalziation\n",
      "./logs/poverty_fold:A_\n",
      "best_epoch=9\n",
      "best_val_metric=0.558316540283777\n",
      "100%|█████████████████████████████████████████| 154/154 [01:40<00:00,  1.53it/s]\n",
      "Eval split train at epoch 9:\n",
      "Average mse: 0.198\n",
      "  urban = 0  [n =   6258]:\tmse = 0.159\n",
      "  urban = 1  [n =   3539]:\tmse = 0.267\n",
      "Worst-group mse: 0.267\n",
      "Average r: 0.848\n",
      "  urban = 0  [n =   6258]:\tr = 0.692\n",
      "  urban = 1  [n =   3539]:\tr = 0.688\n",
      "Worst-group r: 0.688\n",
      "100%|███████████████████████████████████████████| 16/16 [00:11<00:00,  1.45it/s]\n",
      "Eval split id_val at epoch 9:\n",
      "Average mse: 0.217\n",
      "  urban = 0  [n =    630]:\tmse = 0.188\n",
      "  urban = 1  [n =    370]:\tmse = 0.266\n",
      "Worst-group mse: 0.266\n",
      "Average r: 0.834\n",
      "  urban = 0  [n =    630]:\tr = 0.665\n",
      "  urban = 1  [n =    370]:\tr = 0.679\n",
      "Worst-group r: 0.665\n",
      "100%|███████████████████████████████████████████| 16/16 [00:11<00:00,  1.45it/s]\n",
      "Eval split id_test at epoch 9:\n",
      "Average mse: 0.208\n",
      "  urban = 0  [n =    645]:\tmse = 0.158\n",
      "  urban = 1  [n =    355]:\tmse = 0.300\n",
      "Worst-group mse: 0.300\n",
      "Average r: 0.844\n",
      "  urban = 0  [n =    645]:\tr = 0.691\n",
      "  urban = 1  [n =    355]:\tr = 0.673\n",
      "Worst-group r: 0.673\n",
      "100%|███████████████████████████████████████████| 62/62 [00:38<00:00,  1.59it/s]\n",
      "Eval split val at epoch 9:\n",
      "Average mse: 0.227\n",
      "  urban = 0  [n =   2688]:\tmse = 0.189\n",
      "  urban = 1  [n =   1221]:\tmse = 0.311\n",
      "Worst-group mse: 0.311\n",
      "Average r: 0.823\n",
      "  urban = 0  [n =   2688]:\tr = 0.558\n",
      "  urban = 1  [n =   1221]:\tr = 0.675\n",
      "Worst-group r: 0.558\n",
      "100%|███████████████████████████████████████████| 62/62 [00:39<00:00,  1.57it/s]\n",
      "Eval split test at epoch 9:\n",
      "Average mse: 0.343\n",
      "  urban = 0  [n =   2647]:\tmse = 0.351\n",
      "  urban = 1  [n =   1316]:\tmse = 0.325\n",
      "Worst-group mse: 0.351\n",
      "Average r: 0.817\n",
      "  urban = 0  [n =   2647]:\tr = 0.417\n",
      "  urban = 1  [n =   1316]:\tr = 0.614\n",
      "Worst-group r: 0.417\n"
     ]
    }
   ],
   "source": [
    "!python examples/run_expt.py --eval_only --dataset poverty --algorithm ERM --root_dir data --model vit_b_16 --progress_bar --n_epochs 10\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processing split=id_val, replicate=fold:A, predictions_file=poverty_split:id_val_fold:A_epoch:9_pred.csv...\n",
      "Traceback (most recent call last):\n",
      "  File \"/home/ubuntu/wilds/examples/evaluate.py\", line 299, in <module>\n",
      "    main()\n",
      "  File \"/home/ubuntu/wilds/examples/evaluate.py\", line 261, in main\n",
      "    evaluate_benchmark(\n",
      "  File \"/home/ubuntu/wilds/examples/evaluate.py\", line 145, in evaluate_benchmark\n",
      "    predictions_file = get_prediction_file(\n",
      "  File \"/home/ubuntu/wilds/examples/evaluate.py\", line 93, in get_prediction_file\n",
      "    raise FileNotFoundError(\n",
      "FileNotFoundError: Could not find CSV or pth prediction file that starts with poverty_split:id_val_fold:B.\n"
     ]
    }
   ],
   "source": [
    "!python examples/evaluate.py examples/logs/ examples/evaluation/ --root_dir data/ --dataset poverty\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.10/site-packages/torchvision/io/image.py:13: UserWarning: Failed to load image Python extension: '/opt/conda/lib/python3.10/site-packages/torchvision/image.so: undefined symbol: _ZN3c1017RegisterOperatorsD1Ev'If you don't plan on using image functionality from `torchvision.io`, you can ignore this warning. Otherwise, there might be something wrong with your environment. Did you have `libjpeg` or `libpng` installed before building `torchvision` from source?\n",
      "  warn(\n"
     ]
    }
   ],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# conv_proj = nn.Conv2d(\n",
    "#                 in_channels=3, out_channels=hidden_dim, kernel_size=patch_size, stride=patch_size\n",
    "#             )\n",
    "\n",
    "vit = torchvision.models.vit_b_16(weights=\"DEFAULT\") "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "VisionTransformer(\n",
       "  (conv_proj): Conv2d(8, 768, kernel_size=(16, 16), stride=(16, 16))\n",
       "  (encoder): Encoder(\n",
       "    (dropout): Dropout(p=0.0, inplace=False)\n",
       "    (layers): Sequential(\n",
       "      (encoder_layer_0): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_1): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_2): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_3): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_4): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_5): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_6): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_7): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_8): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_9): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_10): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "      (encoder_layer_11): EncoderBlock(\n",
       "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (self_attention): MultiheadAttention(\n",
       "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
       "        )\n",
       "        (dropout): Dropout(p=0.0, inplace=False)\n",
       "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "        (mlp): MLPBlock(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU(approximate='none')\n",
       "          (2): Dropout(p=0.0, inplace=False)\n",
       "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
       "          (4): Dropout(p=0.0, inplace=False)\n",
       "        )\n",
       "      )\n",
       "    )\n",
       "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
       "  )\n",
       "  (heads): Sequential(\n",
       "    (head): Linear(in_features=768, out_features=1000, bias=True)\n",
       "  )\n",
       ")"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vit.conv_proj = nn.Conv2d(\n",
    "                 in_channels=8, out_channels=768, kernel_size=(16, 16), stride=(16, 16)\n",
    "             )\n",
    "vit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.3.0+cu121\n",
      "8500\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "print(torch.__version__)\n",
    "print(torch.backends.cudnn.version())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.cuda.is_available()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'12.1'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.version.cuda"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
