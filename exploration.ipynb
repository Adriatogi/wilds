{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset: poverty\n",
      "Algorithm: VIT\n",
      "Root dir: data\n",
      "Split scheme: official\n",
      "Dataset kwargs: {'no_nl': False, 'fold': 'A', 'use_ood_val': True}\n",
      "Download: False\n",
      "Frac: 1.0\n",
      "Version: None\n",
      "Unlabeled split: None\n",
      "Unlabeled version: None\n",
      "Use unlabeled y: False\n",
      "Loader kwargs: {'num_workers': 4, 'pin_memory': True}\n",
      "Unlabeled loader kwargs: {'num_workers': 8, 'pin_memory': True}\n",
      "Train loader: standard\n",
      "Uniform over groups: False\n",
      "Distinct groups: None\n",
      "N groups per batch: 8\n",
      "Unlabeled n groups per batch: 4\n",
      "Batch size: 64\n",
      "Unlabeled batch size: 64\n",
      "Eval loader: standard\n",
      "Gradient accumulation steps: 1\n",
      "Model: vit_b_16\n",
      "Model kwargs: {'num_channels': 8}\n",
      "Noisystudent add dropout: None\n",
      "Noisystudent dropout rate: None\n",
      "Pretrained model path: None\n",
      "Load featurizer only: False\n",
      "Teacher model path: None\n",
      "Transform: poverty\n",
      "Additional train transform: None\n",
      "Target resolution: None\n",
      "Resize scale: None\n",
      "Max token length: None\n",
      "Randaugment n: 2\n",
      "Loss function: mse\n",
      "Loss kwargs: {}\n",
      "Groupby fields: ['country']\n",
      "Group dro step size: None\n",
      "Coral penalty weight: 0.1\n",
      "Dann penalty weight: 0.1\n",
      "Dann classifier lr: 0.001\n",
      "Dann featurizer lr: 0.0001\n",
      "Dann discriminator lr: 0.001\n",
      "Afn penalty weight: None\n",
      "Safn delta r: None\n",
      "Hafn r: None\n",
      "Use hafn: False\n",
      "Irm lambda: 1.0\n",
      "Irm penalty anneal iters: None\n",
      "Self training lambda: None\n",
      "Self training threshold: None\n",
      "Pseudolabel t2: None\n",
      "Soft pseudolabels: False\n",
      "Algo log metric: mse\n",
      "Process pseudolabels function: pseudolabel_identity\n",
      "Val metric: r_wg\n",
      "Val metric decreasing: False\n",
      "N epochs: 200\n",
      "Optimizer: Adam\n",
      "Lr: 0.001\n",
      "Weight decay: 0.0\n",
      "Max grad norm: 1.0\n",
      "Optimizer kwargs: {}\n",
      "Scheduler: StepLR\n",
      "Scheduler kwargs: {'gamma': 0.96, 'step_size': 1}\n",
      "Scheduler metric split: val\n",
      "Scheduler metric name: None\n",
      "Process outputs function: None\n",
      "Evaluate all splits: True\n",
      "Eval splits: []\n",
      "Eval only: False\n",
      "Eval epoch: None\n",
      "Device: cpu\n",
      "Seed: 0\n",
      "Log dir: ./logs\n",
      "Log every: 50\n",
      "Save step: None\n",
      "Save best: True\n",
      "Save last: True\n",
      "Save pred: True\n",
      "No group logging: False\n",
      "Progress bar: False\n",
      "Resume: False\n",
      "Use wandb: False\n",
      "Wandb api key path: None\n",
      "Wandb kwargs: {}\n",
      "Use data parallel: False\n",
      "\n",
      "type(datasets[split]['dataset'])=<class 'wilds.datasets.wilds_dataset.WILDSSubset'>\n",
      "Train data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 484\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 394\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 501\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 1535\n",
      "    country = lesotho: n = 658\n",
      "    country = malawi: n = 1614\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 741\n",
      "    country = nigeria: n = 1206\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 488\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 274\n",
      "    country = uganda: n = 638\n",
      "    country = zambia: n = 586\n",
      "    country = zimbabwe: n = 678\n",
      "ID Val data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 45\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 49\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 59\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 141\n",
      "    country = lesotho: n = 66\n",
      "    country = malawi: n = 171\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 72\n",
      "    country = nigeria: n = 121\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 47\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 32\n",
      "    country = uganda: n = 67\n",
      "    country = zambia: n = 63\n",
      "    country = zimbabwe: n = 67\n",
      "ID Test data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 47\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 49\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 54\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 154\n",
      "    country = lesotho: n = 70\n",
      "    country = malawi: n = 172\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 66\n",
      "    country = nigeria: n = 123\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 50\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 24\n",
      "    country = uganda: n = 73\n",
      "    country = zambia: n = 70\n",
      "    country = zimbabwe: n = 48\n",
      "OOD Val data...\n",
      "    country = angola: n = 0\n",
      "    country = benin: n = 746\n",
      "    country = burkina_faso: n = 789\n",
      "    country = cameroon: n = 0\n",
      "    country = cote_d_ivoire: n = 0\n",
      "    country = democratic_republic_of_congo: n = 0\n",
      "    country = ethiopia: n = 0\n",
      "    country = ghana: n = 0\n",
      "    country = guinea: n = 300\n",
      "    country = kenya: n = 0\n",
      "    country = lesotho: n = 0\n",
      "    country = malawi: n = 0\n",
      "    country = mali: n = 0\n",
      "    country = mozambique: n = 0\n",
      "    country = nigeria: n = 0\n",
      "    country = rwanda: n = 0\n",
      "    country = senegal: n = 0\n",
      "    country = sierra_leone: n = 435\n",
      "    country = tanzania: n = 1639\n",
      "    country = togo: n = 0\n",
      "    country = uganda: n = 0\n",
      "    country = zambia: n = 0\n",
      "    country = zimbabwe: n = 0\n",
      "OOD Test data...\n",
      "    country = angola: n = 855\n",
      "    country = benin: n = 0\n",
      "    country = burkina_faso: n = 0\n",
      "    country = cameroon: n = 0\n",
      "    country = cote_d_ivoire: n = 341\n",
      "    country = democratic_republic_of_congo: n = 0\n",
      "    country = ethiopia: n = 1193\n",
      "    country = ghana: n = 0\n",
      "    country = guinea: n = 0\n",
      "    country = kenya: n = 0\n",
      "    country = lesotho: n = 0\n",
      "    country = malawi: n = 0\n",
      "    country = mali: n = 590\n",
      "    country = mozambique: n = 0\n",
      "    country = nigeria: n = 0\n",
      "    country = rwanda: n = 984\n",
      "    country = senegal: n = 0\n",
      "    country = sierra_leone: n = 0\n",
      "    country = tanzania: n = 0\n",
      "    country = togo: n = 0\n",
      "    country = uganda: n = 0\n",
      "    country = zambia: n = 0\n",
      "    country = zimbabwe: n = 0\n",
      "len(train_dataset)=9797\n",
      "vit_b_16 model inititalziation\n",
      "VisionTransformer(\n",
      "  (conv_proj): Conv2d(3, 768, kernel_size=(16, 16), stride=(16, 16))\n",
      "  (encoder): Encoder(\n",
      "    (dropout): Dropout(p=0.0, inplace=False)\n",
      "    (layers): Sequential(\n",
      "      (encoder_layer_0): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_1): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_2): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_3): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_4): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_5): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_6): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_7): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_8): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_9): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_10): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "      (encoder_layer_11): EncoderBlock(\n",
      "        (ln_1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (self_attention): MultiheadAttention(\n",
      "          (out_proj): NonDynamicallyQuantizableLinear(in_features=768, out_features=768, bias=True)\n",
      "        )\n",
      "        (dropout): Dropout(p=0.0, inplace=False)\n",
      "        (ln_2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): MLPBlock(\n",
      "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (1): GELU(approximate='none')\n",
      "          (2): Dropout(p=0.0, inplace=False)\n",
      "          (3): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (4): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (ln): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "  )\n",
      "  (heads): Sequential(\n",
      "    (head): Linear(in_features=768, out_features=1, bias=True)\n",
      "  )\n",
      ")\n",
      "Traceback (most recent call last):\n",
      "  File \"/Users/adriangamarra/Documents/GitHub/wilds/examples/run_expt.py\", line 483, in <module>\n",
      "    main()\n",
      "  File \"/Users/adriangamarra/Documents/GitHub/wilds/examples/run_expt.py\", line 405, in main\n",
      "    algorithm = initialize_algorithm(\n",
      "  File \"/Users/adriangamarra/Documents/GitHub/wilds/examples/algorithms/initializer.py\", line 30, in initialize_algorithm\n",
      "    algorithm = VIT(\n",
      "  File \"/Users/adriangamarra/Documents/GitHub/wilds/examples/algorithms/VIT.py\", line 21, in __init__\n",
      "    sys.exit(0)\n",
      "NameError: name 'sys' is not defined\n"
     ]
    }
   ],
   "source": [
    "!python examples/run_expt.py --dataset poverty --algorithm VIT --root_dir data --model vit_b_16\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torchvision\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
